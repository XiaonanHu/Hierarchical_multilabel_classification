import tensorflow_hub as hub
import os
import tensorflow.compat.v1 as tf1
tf1.disable_eager_execution()
import tensorflow as tf
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore")


def extract_features(patent_data, extractor):
    embedding = {}

    if extractor == "Universal_Encoder":
        # embed every word into a 1*1024 vector
        # e.g. 63 words in abstract, the abstract embedding is 63*1024
        path = os.path.abspath(os.path.dirname(os.getcwd()))
        embed = hub.Module(path + "/Universal_Encoder")
        for patent_index in tqdm(patent_data.keys()):
            title = patent_data[patent_index]['title']
            abstract = patent_data[patent_index]['abstract']
            description = patent_data[patent_index]['description']

            # merge all titles
            title = title[0] + ' '+ title[1] + ' ' + title[2]

            # embeddings
            #             # title_embedding = []
            #             # abstract_embedding = []
            #             # description_embedding = []
            #             # sess = tf.Session()
            #             # with sess.as_default():
            #             #     for word in title.split(' '):
            #             #         title_embedding.append(embed([word]))
            #             #     for word in abstract.split(' '):
            #             #         abstract.append(embed(word))
            #             #     for word in description.split(' '):
            #             #         description_embedding.append(embed(word))

            title_embedding = embed(title.split(' ')[:30])
            abstract_embedding = embed(abstract.split(' ')[:30])
            description_embedding = embed(description.split(' ')[:30])
            sess = tf.Session()
            with sess.as_default():
                title_embedding = title_embedding.eval()
                abstract_embedding = abstract_embedding.eval()
                description_embedding = description_embedding.eval()
            embedding[patent_index] = {'title': title_embedding, 'abstract': abstract_embedding, 'description': description_embedding}


    return embedding




def extract_features(patent_data, extractor, K = None):
    embedding = {}
    if extractor == "glove":
        """
        the features generated by this method is not fixed.
        """
        # load model. It might take a while.
        glove_model = KeyedVectors.load_word2vec_format("../pretrained_model/glove/glove.twitter.27B/glove.twitter.27B.25d.word2vec.txt", binary=False)

        for patent_index in tqdm(patent_data.keys()):
            title = patent_data[patent_index]['title']
            abstract = patent_data[patent_index]['abstract']
            description = patent_data[patent_index]['description']
            # merge all titles
            title = title[0] + ' '+ title[1] + ' ' + title[2]

            # get embeddings
            title_embedding = []
            abstract_embedding = []
            description_embedding = []
            for word in title.split(' '):
                if not word in glove_model.wv.vocab:
                    continue
                title_embedding.append(glove_model[word])
            for word in abstract.split(' '):
                if not word in glove_model.wv.vocab:
                    continue
                abstract_embedding.append(glove_model[word])
            for word in description.split(' '):
                if not word in glove_model.wv.vocab:
                    continue
                description_embedding.append(glove_model[word])

            title_embedding = np.array(title_embedding)
            abstract_embedding = np.array(abstract_embedding)
            description_embedding = np.array(description_embedding)

            embedding[patent_index] = {'title': title_embedding,
                                       'abstract': abstract_embedding,
                                       'description': description_embedding}
            if 'labels' in patent_data[patent_index].keys():
                embedding[patent_index]['labels'] = patent_data[patent_index]['labels']

    elif extractor == "tfidf+glove":
        """
        First use tf-idf to find the top K most informative words in mixture of title, abstract and description.
        Then the glove is utilized to find embeddings for these words.
        """
        # load model. It might take a while.
        glove_model = KeyedVectors.load_word2vec_format(
            "../pretrained_model/glove/glove.twitter.27B/glove.twitter.27B.25d.word2vec.txt", binary=False)

        # Concatenate title, abstract and description into text. Save patent index and its text.
        corpus = []
        patent_index_list = []
        for patent_index in tqdm(patent_data.keys()):
            title = patent_data[patent_index]['title']
            abstract = patent_data[patent_index]['abstract']
            description = patent_data[patent_index]['description']
            # merge all titles
            title = title[0] + ' '+ title[1] + ' ' + title[2]
            text = title + ' ' + abstract + ' ' + description
            corpus.append(text)
            patent_index_list.append(patent_index)

        # tf-idf
        vectorizer = CountVectorizer()
        transformer = TfidfTransformer()
        tfidf = transformer.fit_transform(vectorizer.fit_transform(corpus))
        # find all nonzero tf-idf score
        nonzero_index = tfidf.nonzero()
        sorted_index = {}
        for i in range(len(nonzero_index[0])):
            r = nonzero_index[0][i]
            c = nonzero_index[1][i]
            tfidf_score = tfidf[r][c]
            patent_index = patent_index_list[r]
            if not patent_index in sorted_index.keys():
                sorted_index[patent_index] = [[c,tfidf_score]]
            else:
                sorted_index[patent_index].append([c,tfidf_score])
        # find the K words with highest tf-idf score
        for patent_index in sorted_index.keys():
            sorted_index[patent_index].sort(key=takeSecond,reverse=True)
        # get all the words
        bag_of_words = vectorizer.get_feature_names()


        embedding = {}
        for i in tqdm(range(len(patent_index_list))):
            embedding_num = 0
            patent_embedding = []
            for informative_word_index in sorted_index[patent_index[i]]:
                if not bag_of_words[informative_word_index[0]] in glove_model.wv.vocab:
                    continue
                patent_embedding.append(glove_model[bag_of_words[informative_word_index[0]]])
                embedding_num += 1
                if embedding_num == K:
                    break
            patent_embedding = np.array(patent_embedding)
            embedding[patent_index_list[i]] = patent_embedding

        print(tfidf)

    return embedding




if __name__ == "__main__":
    from get_data import load_data_small
    import os
    labeled_patent_data, unlabeled_patent_data = load_data_small()
    print("number of patent:", len(labeled_patent_data))
    features = extract_features(labeled_patent_data, extractor="Universal_Encoder")
    os.system("pause")